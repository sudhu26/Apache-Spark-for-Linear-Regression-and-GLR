{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Walmart Sales Forecasting\n",
    "**Phase III: Model Training**\n",
    "\n",
    "@author: Syed Shahzad Raza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-required-dependencies\" data-toc-modified-id=\"Import-required-dependencies-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import required dependencies</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Indexing,-Encoding-and-Scaling\" data-toc-modified-id=\"Indexing,-Encoding-and-Scaling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Indexing, Encoding and Scaling</a></span></li><li><span><a href=\"#Create-Checkpoint-for-Phase-IV\" data-toc-modified-id=\"Create-Checkpoint-for-Phase-IV-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create Checkpoint for Phase IV</a></span></li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Linear Regression</a></span></li><li><span><a href=\"#Hyper-parameter-tuning-for-Linear-Regression\" data-toc-modified-id=\"Hyper-parameter-tuning-for-Linear-Regression-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Hyper-parameter tuning for Linear Regression</a></span></li><li><span><a href=\"#Generalized-Linear-Regression\" data-toc-modified-id=\"Generalized-Linear-Regression-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Generalized Linear Regression</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from saved file\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").option('inferSchema', 'true').load(\"phase_2_train_df.csv\")\n",
    "test_df = spark.read.format(\"csv\").option(\"header\", \"true\").option('inferSchema', 'true').load(\"phase_2_test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Encoding and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validate sets\n",
    "(train_df, validate_df) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = train_df.columns\n",
    "cat_vars = ['Store', 'Dept', 'IsHoliday', 'Type']\n",
    "target_value = 'label'\n",
    "cont_vars = [x for x in all_vars if x not in cat_vars]\n",
    "cont_vars = [x for x in cont_vars if x not in target_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "                 for c in cat_vars ]\n",
    "\n",
    "encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "                 for indexer in indexers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                                + cont_vars, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledfeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Checkpoint for Phase IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for Phase III\n",
    "train_df.toPandas().to_csv('phase_3_train_df.csv', index=False)\n",
    "validate_df.toPandas().to_csv('phase_3_validate_df.csv', index=False)\n",
    "test_df.toPandas().to_csv('phase_3_test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression model\n",
    "lr = LinearRegression(labelCol=\"label\", featuresCol=\"scaledfeatures\", maxIter=10, regParam=0.1, elasticNetParam=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chain indexer, encoder, assembler, scaler and linear regression in a pipeline\n",
    "pipeline = Pipeline(stages = indexers + encoders + [assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear regression model on training data\n",
    "LR_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "path = \"LR_model\"\n",
    "LR_model.write().overwrite().save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression model\n",
    "lr2 = LinearRegression(labelCol=\"label\", featuresCol=\"scaledfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chain indexer, encoder, assembler, scaler and linear regression in a pipeline\n",
    "pipeline = Pipeline(stages = indexers + encoders + [assembler, scaler, lr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a ParamGridBuilder to construct a grid of parameters to search over\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .addGrid(lr.maxIter, [10,15,20])\\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 0.8, 1.0])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainValidationSplit will try all combinations of values from ParamGridBuilder and determine \n",
    "# best model using the evaluator\n",
    "valid = TrainValidationSplit(estimator=pipeline,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator=RegressionEvaluator(),\n",
    "                             trainRatio=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TrainValidationSplit, and choose the best set of parameters\n",
    "tvs_model = valid.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "path = \"tvs_model\"\n",
    "tvs_bestModel = tvs_model.bestModel\n",
    "tvs_bestModel.write().overwrite().save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a generalized linear regression model\n",
    "glr = GeneralizedLinearRegression(featuresCol=\"scaledfeatures\", family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chain indexer, encoder, assembler, scaler and generalized linear regression in a pipeline\n",
    "pipeline = Pipeline(stages = indexers + encoders + [assembler, scaler, glr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit generalized linear regression model on training data\n",
    "GLR_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "path = \"GLR_model\"\n",
    "GLR_model.write().overwrite().save(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
